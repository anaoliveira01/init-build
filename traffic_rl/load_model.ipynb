{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load RL Policy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Policy\n",
    "\n",
    "### Policy Options\n",
    "\n",
    "- [Documentation](https://docs.ray.io/en/latest/rllib/rllib-saving-and-loading-algos-and-policies.html)\n",
    "- `policy_dir` is the path to the last version of our policy and its weights\n",
    "- `checkpoint_dir` is the path to the last checkpoint from our training process. \n",
    "- We won't be using `checkpoint_dir`, but it's useful for restoring to the previous state and configuration, allowing us to continue training if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ef4444\">\n",
    "&#x2B55; When loading in these checkpoints it's best to use the same version of python used in the training environment.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"sumo_3d_demo/ray_results/Sheridan/PPO/PPO_Sheridan_0c5d9_00000_0_2024-11-26_15-42-31/checkpoint_000018\"\n",
    "\n",
    "policy_dir = \"sumo_3d_demo/ray_results/Sheridan/PPO/PPO_Sheridan_0c5d9_00000_0_2024-11-26_15-42-31/checkpoint_000018/policies/default_policy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to load any policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPOTorchPolicy\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.policy.policy import Policy\n",
    "\n",
    "policy = Policy.from_checkpoint(policy_dir)\n",
    "\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to load any Algorithm checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "algorithm = Algorithm.from_checkpoint(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load PPO policy for SUMO\n",
    "\n",
    "\n",
    "### Explanation of the Code\n",
    "\n",
    "1. **Import Required Libraries**:  \n",
    "   - `sumo_rl`: Used to interact with the SUMO simulation environment.  \n",
    "   - `ray.rllib.policy`: For loading and using a pre-trained RL policy.  \n",
    "   - `numpy`: Handles numerical operations like array transformations.  \n",
    "\n",
    "2. **Load Pre-trained Policy**:  \n",
    "   - The policy is loaded from our last checkpoint using `Policy.from_checkpoint(policy_dir)`.\n",
    "\n",
    "3. **Initialize SUMO-RL Environment**:  \n",
    "   - The SUMO simulation requires a network file (`osm.net.xml`) and a route file (`osm.rou.xml`).  \n",
    "   - GUI is enabled, and the simulation runs for up to 80,000 seconds.\n",
    "\n",
    "4. **Environment Reset**:  \n",
    "   - The environment is reset using `env.reset()`, providing initial observations (`observations`) for all agents.\n",
    "\n",
    "5. **Action Loop**:  \n",
    "   - While agents are active in the environment:  \n",
    "     - **Action Computation**: For each agent:  \n",
    "       - Observations are converted to a NumPy array (`obs_array`) for compatibility.  \n",
    "       - The pre-trained policy computes actions based on observations using `policy.compute_single_action()`.  \n",
    "     - **Environment Step**:  \n",
    "       - The computed actions are passed to the environment using `env.step(actions)`, which returns:  \n",
    "         - `observations`: New state information for agents.  \n",
    "         - `rewards`: Immediate rewards for actions.  \n",
    "         - `terminations` and `truncations`: Flags indicating if agents have completed or are truncated.  \n",
    "         - `infos`: Additional environment data.  \n",
    "\n",
    "6. **Reward Logging**:  \n",
    "   - Rewards for each agent are printed for monitoring performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sumo_rl\n",
    "import numpy as np\n",
    "from ray.rllib.policy.policy import Policy\n",
    "\n",
    "policy = Policy.from_checkpoint(policy_dir)\n",
    "\n",
    "# Initialize SUMO-RL environment\n",
    "env = sumo_rl.parallel_env(\n",
    "    net_file='sumo_3d_demo/osm.net.xml',\n",
    "    route_file='sumo_3d_demo/osm.rou.xml',\n",
    "    use_gui=True,\n",
    "    num_seconds=80000\n",
    ")\n",
    "\n",
    "# Reset the environment\n",
    "observations, infos = env.reset()\n",
    "\n",
    "while env.agents:\n",
    "    # Compute actions using the loaded policy\n",
    "    actions = {}\n",
    "    for agent, obs in observations.items():\n",
    "        # Convert observation to appropriate format\n",
    "        obs_array = np.array(obs).astype(np.float32)\n",
    "        \n",
    "        # Compute the action using the policy\n",
    "        # Extract only the action\n",
    "        action, _, _ = policy.compute_single_action(obs_array) \n",
    "\n",
    "        actions[agent] = action\n",
    "    \n",
    "    # Step the environment\n",
    "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "    \n",
    "    # Optional: Log rewards or other metrics\n",
    "    for agent, reward in rewards.items():\n",
    "        print(f\"Agent: {agent}, Reward: {reward}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run 3D Unity Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before we can run the Unity script we need to modify our sumo_rl custom launcher.\n",
    "- In the modified script we're forcing the traci server to port 4001 and reducing the step length to 0.5.\n",
    "- We also ensure we specify the exection order so our policy takes priority over the Unity script.\n",
    "- This Unity script is from [traffic3d](https://traffic3d.org/sumo.html)\n",
    "  - Make sure to install traffic3d and go through a test run\n",
    "  - Once that's working fine we can modify it to account for our policy script\n",
    "  - In the `Scripts` folder modify the following:\n",
    "    - `ControlCommands.cs`: change `CMD_GETVERSION` TO `CMD_SETORDER`\n",
    "    - Then in `SumoManager.cs` add the following to the if statement on line 44: `client.Control.SetOrder(1);`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced /Users/jamesb/.pyenv/versions/3.10.12/lib/python3.10/site-packages/sumo_rl/environment/env.py with your modified `env.py` from modified_env.py\n"
     ]
    }
   ],
   "source": [
    "import sumo_rl\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# Get the path of the installed `sumo_rl` package\n",
    "sumo_rl_path = Path(sumo_rl.__file__).parent\n",
    "\n",
    "# Path to the existing `env.py` file in the installed package\n",
    "original_env_path = sumo_rl_path / \"environment\" / \"env.py\"\n",
    "\n",
    "# Path to your modified `env.py` file (placed in the same directory as your notebook)\n",
    "modified_env_path = Path(\"modified_env.py\")\n",
    "\n",
    "# Ensure the modified file exists\n",
    "if not modified_env_path.exists():\n",
    "    raise FileNotFoundError(f\"Modified env.py not found at {modified_env_path}\")\n",
    "\n",
    "# Overwrite the installed `env.py` with the modified version\n",
    "shutil.copy(modified_env_path, original_env_path)\n",
    "print(f\"Replaced {original_env_path} with your modified `env.py` from {modified_env_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:#ef4444\">\n",
    "&#x2B55; After running the previous script you have to restart your kernel\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_dir = \"sumo_3d_demo/ray_results/Sheridan/PPO/PPO_Sheridan_0c5d9_00000_0_2024-11-26_15-42-31/checkpoint_000018/policies/default_policy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Step #0.00 (0ms ?*RT. ?UPS, TraCI: 9ms, vehicles TOT 0 ACT 0 BUF 0)                      \n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jamesb/.pyenv/versions/3.10.12/lib/python3.10/site-packages/pettingzoo/utils/conversions.py:132: UserWarning: The base environment `sumo_rl_v0` does not have a `render_mode` defined.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import sumo_rl\n",
    "import numpy as np\n",
    "from ray.rllib.policy.policy import Policy\n",
    "\n",
    "policy = Policy.from_checkpoint(policy_dir)\n",
    "\n",
    "# Initialize SUMO-RL environment with multiple client support\n",
    "env = sumo_rl.parallel_env(\n",
    "    net_file='sumo_3d_demo/osm.net.xml',\n",
    "    route_file='sumo_3d_demo/osm.rou.xml',\n",
    "    use_gui=True,\n",
    "    num_seconds=80000,\n",
    "    port=4001,          # Use the same port for SUMO and Unity\n",
    "    num_clients=2,      # Allow two clients (policy script and Unity)\n",
    ")\n",
    "# Reset the environment\n",
    "observations, infos = env.reset()\n",
    "\n",
    "while env.agents:\n",
    "    # Compute actions using the loaded policy\n",
    "    actions = {}\n",
    "    for agent, obs in observations.items():\n",
    "        # Convert observation to appropriate format\n",
    "        obs_array = np.array(obs).astype(np.float32)\n",
    "        \n",
    "        # Compute the action using the policy\n",
    "        # Extract only the action\n",
    "        action, _, _ = policy.compute_single_action(obs_array) \n",
    "\n",
    "        actions[agent] = action\n",
    "    \n",
    "    # Step the environment\n",
    "    observations, rewards, terminations, truncations, infos = env.step(actions)\n",
    "    \n",
    "    # Optional: Log rewards or other metrics\n",
    "    for agent, reward in rewards.items():\n",
    "        print(f\"Agent: {agent}, Reward: {reward}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "Could not connect to TraCI server at localhost:4001 [Errno 61] Connection refused\n",
      " Retrying in 1 seconds\n",
      "Could not connect to TraCI server at localhost:4001 [Errno 61] Connection refused\n",
      " Retrying in 1 seconds\n",
      "Could not connect to TraCI server at localhost:4001 [Errno 61] Connection refused\n",
      " Retrying in 1 seconds\n",
      "Could not connect to TraCI server at localhost:4001 [Errno 61] Connection refused\n",
      " Retrying in 1 seconds\n",
      "Could not connect to TraCI server at localhost:4001 [Errno 61] Connection refused\n",
      " Retrying in 1 seconds\n",
      "Could not connect to TraCI server at localhost:4001 [Errno 61] Connection refused\n",
      " Retrying in 1 seconds\n",
      "Could not connect to TraCI server at localhost:4001 [Errno 61] Connection refused\n",
      " Retrying in 1 seconds\n",
      "Could not connect to TraCI server at localhost:4001 [Errno 61] Connection refused\n",
      " Retrying in 1 seconds\n",
      "Could not connect to TraCI server at localhost:4001 [Errno 61] Connection refused\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/traci/main.py:97\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(port, numRetries, host, proc, waitBetweenRetries, traceFile, traceGetters, label)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConnection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceGetters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/traci/connection.py:83\u001b[0m, in \u001b[0;36mConnection.__init__\u001b[0;34m(self, host, port, process, traceFile, traceGetters, label)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_socket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror:\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Connect to the existing SUMO instance\u001b[39;00m\n\u001b[1;32m      5\u001b[0m traci_port \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4001\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtraci\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraci_port\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Set the execution order for this client (e.g., 0 for Python client)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m traci\u001b[38;5;241m.\u001b[39msetOrder(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/traci/main.py:116\u001b[0m, in \u001b[0;36minit\u001b[0;34m(port, numRetries, host, label, proc, doSwitch, traceFile, traceGetters)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit\u001b[39m(port\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8813\u001b[39m, numRetries\u001b[38;5;241m=\u001b[39mtc\u001b[38;5;241m.\u001b[39mDEFAULT_NUM_RETRIES, host\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m\"\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m, proc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, doSwitch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    110\u001b[0m          traceFile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, traceGetters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    Establish a connection to a TraCI-Server and store it under the given\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    label. This method is not thread-safe. It accesses the connection\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;124;03m    pool concurrently.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     con \u001b[38;5;241m=\u001b[39m \u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumRetries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceFile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceGetters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m doSwitch:\n\u001b[1;32m    118\u001b[0m         switch(label)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/traci/main.py:105\u001b[0m, in \u001b[0;36mconnect\u001b[0;34m(port, numRetries, host, proc, waitBetweenRetries, traceFile, traceGetters, label)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m retry \u001b[38;5;241m<\u001b[39m numRetries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Retrying in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m waitBetweenRetries)\n\u001b[0;32m--> 105\u001b[0m             \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaitBetweenRetries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m FatalTraCIError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not connect in \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m tries\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (numRetries \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import traci\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the existing SUMO instance\n",
    "traci_port = 4001\n",
    "traci.init(traci_port)\n",
    "\n",
    "# Set the execution order for this client (e.g., 0 for Python client)\n",
    "traci.setOrder(0)\n",
    "\n",
    "# Get the list of traffic light IDs\n",
    "tls_ids = traci.trafficlight.getIDList()\n",
    "\n",
    "\n",
    "while True:\n",
    "\n",
    "    traci.simulationStep()\n",
    "\n",
    "# Close the connection when done\n",
    "traci.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
